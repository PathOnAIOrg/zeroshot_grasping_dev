# Grasp Pose Visualizer

A web-based visualization tool for 6DOF robotic grasp poses and point clouds. Supports direct integration with ThinkGrasp outputs and provides real-time 3D visualization using Three.js.

## Features

- **Point Cloud Visualization**: Display point clouds from PLY files or reconstruct from RGB-D images
- **Grasp Pose Rendering**: Visualize 6DOF grasp poses with realistic gripper geometry
- **Multiple Input Methods**:
  - Upload PLY point cloud + NPY grasp array (ThinkGrasp format)
  - Reconstruct from RGB-D images + grasp poses JSON
  - Direct JSON input for quick visualization
- **ThinkGrasp Integration**: Native support for ThinkGrasp coordinate systems and data formats
- **Interactive 3D Controls**: Rotate, zoom, and pan with mouse controls

## Installation

### Prerequisites
- Python 3.7+
- Node.js (optional, for development)

### Backend Setup

```bash
cd backend
pip install -r requirements.txt
```

Required packages:
- Flask
- Flask-CORS
- NumPy
- OpenCV (cv2)
- Open3D
- Pillow
- SciPy

## Usage

### Starting the Server

```bash
# From project root
python start_server.py

# Or directly from backend
cd backend
python app.py
```

The server runs on `http://localhost:3001`

### Input Methods

#### 1. PLY + NPY Upload (Recommended for ThinkGrasp)
Upload files generated by ThinkGrasp:
- **Point Cloud**: `.ply` file (e.g., `cloud.ply`)
- **Grasp Array**: `.npy` file containing grasp poses in GraspGroup format (17 values per grasp)

#### 2. RGB-D Reconstruction
Upload images and grasp poses:
- **RGB Image**: Color image (JPG/PNG)
- **Depth Image**: 16-bit depth map (PNG)
- **Grasp Poses**: JSON file with grasp pose data

#### 3. Direct JSON Input
Paste grasp poses directly in the text area for quick visualization.

### Data Formats

#### GraspGroup Array Format (NPY)
Each grasp contains 17 values:
```
[score, width, height, depth, rotation_matrix(9), translation(3), object_id]
```

#### JSON Grasp Format
```json
{
  "grasp_poses": [
    {
      "xyz": [0.1, 0.2, 0.3],      // Position (meters)
      "rot": [[...], [...], [...]],  // 3x3 rotation matrix
      "width": 0.08,                 // Gripper width (meters)
      "score": 0.95,                 // Confidence score
      "dep": 0.02                    // Grasp depth
    }
  ]
}
```

### Coordinate System

The visualizer uses camera coordinates:
- **X-axis**: Right (red)
- **Y-axis**: Down (green) 
- **Z-axis**: Forward (blue)

Automatic transformation to Three.js coordinates (Y-up) is handled internally.

## Project Structure

```
grasp_pose_visualizer/
├── backend/
│   ├── app.py                 # Flask server
│   ├── point_cloud_utils.py   # Point cloud processing
│   ├── reconstruct_pointcloud.py  # RGB-D reconstruction
│   ├── simple_transform.py    # PLY/NPY transformation
│   └── unified_transform.py   # Coordinate transformations
├── frontend/
│   └── index.html            # Web interface with Three.js
├── ThinkGrasp/              # ThinkGrasp library (submodule)
├── uploads/                 # Temporary file storage
└── start_server.py         # Server launcher
```

## API Endpoints

- `POST /api/upload_ply_npy` - Upload PLY point cloud and NPY grasp array
- `POST /api/reconstruct_and_visualize` - Reconstruct from RGB-D + grasp poses
- `POST /api/visualize` - Direct JSON visualization
- `GET /` - Web interface

## Camera Configuration

Default camera parameters (can be modified in `point_cloud_utils.py`):
```python
width: 640
height: 480  
fx: 383.9592  # Focal length X
fy: 383.6245  # Focal length Y
cx: 322.1625  # Principal point X
cy: 245.3161  # Principal point Y
depth_scale: 1000.0  # mm to meters
```

## Troubleshooting

### Point cloud and grasps don't align
- Ensure both use the same coordinate system (camera coordinates)
- Check that depth scale matches your depth image format
- Verify camera intrinsics match your capture device

### Visualization is slow
- Reduce point cloud density (automatic downsampling applied)
- Limit number of grasp poses displayed
- Use Chrome/Firefox for best WebGL performance

## License

MIT License