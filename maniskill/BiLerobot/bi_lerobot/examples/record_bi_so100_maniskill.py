#!/usr/bin/env python

# Copyright 2024 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Records a dataset for BiSO100 robot in ManiSkill using LeRobot dataset format.
Actions are generated by teleoperation using real SO100 leader arms OR by a pretrained policy.

Example usage:

**Teleoperator Mode (using real SO100 leader arms):**
```shell
python record_bi_so100_maniskill.py \
    --robot.env_id=BiSO100OpenLid-v1 \
    --robot.leader_ids=left_leader,right_leader \
    --robot.teleop_ports=/dev/ttyACM0,/dev/ttyACM1 \
    --robot.calibration_files="/home/zhiyuan/.cache/huggingface/lerobot/calibration/virtual_robots/bi_so100/left_leader_to_left_arm_interactive.json,/home/zhiyuan/.cache/huggingface/lerobot/calibration/virtual_robots/bi_so100/right_leader_to_right_arm_interactive.json" \
    --dataset.repo_id=username/bi_so100_maniskill_teleop \
    --dataset.num_episodes=10 \
    --dataset.single_task="Open the bottle lid with both arms"
```

**Policy Mode (using a pretrained policy - no teleoperators needed):**
```shell
python record_bi_so100_maniskill.py \
    --robot.env_id=BiSO100OpenLid-v1 \
    --policy.path=path/to/pretrained/policy \
    --dataset.repo_id=username/bi_so100_maniskill_policy \
    --dataset.num_episodes=10 \
    --dataset.single_task="Open the bottle lid with both arms" \
    --display_data=true
```

**Manual Mode (no teleoperators or policy - for testing):**
```shell
python record_bi_so100_maniskill.py \
    --robot.env_id=BiSO100OpenLid-v1 \
    --dataset.repo_id=username/bi_so100_maniskill_manual \
    --dataset.num_episodes=1 \
    --dataset.single_task="Test environment"
```
"""

import json
import logging
import time
from dataclasses import asdict, dataclass, field
from functools import cached_property
from pathlib import Path
from pprint import pformat
from typing import Any, Dict, List

import gymnasium as gym
import numpy as np
import torch

import bi_lerobot
from lerobot.common.datasets.image_writer import safe_stop_image_writer
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from lerobot.common.datasets.utils import build_dataset_frame, hw_to_dataset_features
from lerobot.common.errors import DeviceAlreadyConnectedError, DeviceNotConnectedError
from lerobot.common.policies.factory import make_policy
from lerobot.common.policies.pretrained import PreTrainedPolicy
from lerobot.common.teleoperators import make_teleoperator_from_config
from lerobot.common.teleoperators.so100_leader import SO100LeaderConfig
from lerobot.common.teleoperators import TeleoperatorConfig
from lerobot.common.utils.control_utils import (
    init_keyboard_listener,
    is_headless,
    predict_action,
    sanity_check_dataset_name,
    sanity_check_dataset_robot_compatibility,
)
from lerobot.common.utils.robot_utils import busy_wait
from lerobot.common.utils.utils import get_safe_torch_device, init_logging, log_say
from lerobot.common.utils.visualization_utils import _init_rerun
from lerobot.configs import parser
from lerobot.configs.policies import PreTrainedConfig

try:
    import rerun as rr
    RERUN_AVAILABLE = True
except ImportError:
    RERUN_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class BiSO100RobotConfig:
    """Configuration for BiSO100 robot in ManiSkill"""
    env_id: str = "BiSO100OpenLid-v1"
    robot_uids: str = "bi_so100"
    obs_mode: str = "rgb"
    render_mode: str = "human"
    sim_backend: str = "auto"
    
    # Teleoperator configuration
    leader_ids: List[str] = field(default_factory=lambda: ["left_leader","right_leader"])
    teleop_ports: List[str] = field(default_factory=lambda: ["/dev/ttyACM0","/dev/ttyACM1"])
    calibration_files: List[str] = field(default_factory=lambda: ["/home/zhiyuan/.cache/huggingface/lerobot/calibration/virtual_robots/bi_so100/left_leader_to_left_arm_interactive.json","/home/zhiyuan/.cache/huggingface/lerobot/calibration/virtual_robots/bi_so100/right_leader_to_right_arm_interactive.json"])

    def __post_init__(self):
        if self.leader_ids is not None:
            if isinstance(self.leader_ids, str):
                self.leader_ids = self.leader_ids.split(',')
        if self.teleop_ports is not None:
            if isinstance(self.teleop_ports, str):
                self.teleop_ports = self.teleop_ports.split(',')
        if self.calibration_files is not None:
            if isinstance(self.calibration_files, str):
                self.calibration_files = self.calibration_files.split(',')


@dataclass
class DatasetRecordConfig:
    # Dataset identifier. By convention it should match '{hf_username}/{dataset_name}' (e.g. `lerobot/test`).
    repo_id: str
    # A short but accurate description of the task performed during the recording
    single_task: str
    # Root directory where the dataset will be stored (e.g. 'dataset/path').
    root: str | Path | None = None
    # Limit the frames per second.
    fps: int = 30
    # Number of seconds for data recording for each episode.
    episode_time_s: int | float = 60
    # Number of seconds for resetting the environment after each episode.
    reset_time_s: int | float = 30
    # Number of episodes to record.
    num_episodes: int = 50
    # Encode frames in the dataset into video
    video: bool = True
    # Upload dataset to Hugging Face hub.
    push_to_hub: bool = False
    # Upload on private repository on the Hugging Face hub.
    private: bool = False
    # Add tags to your dataset on the hub.
    tags: list[str] | None = None
    # Number of subprocesses handling the saving of frames as PNG.
    num_image_writer_processes: int = 0
    # Number of threads writing the frames as png images on disk, per camera.
    num_image_writer_threads_per_camera: int = 4

    def __post_init__(self):
        if self.single_task is None:
            raise ValueError("You need to provide a task as argument in `single_task`.")


@dataclass
class RecordConfig:
    robot: BiSO100RobotConfig
    dataset: DatasetRecordConfig
    # Whether to control the robot with a teleoperator
    teleop: TeleoperatorConfig | None = None
    # Whether to control the robot with a policy
    policy: PreTrainedConfig | None = None
    # Display all cameras on screen
    display_data: bool = False
    # Use vocal synthesis to read events.
    play_sounds: bool = True
    # Resume recording on an existing dataset.
    resume: bool = False

    def __post_init__(self):
        # Validate that we have either teleop OR policy (or neither for manual control)
        if self.teleop is not None and self.policy is not None:
            raise ValueError("Cannot use both teleop and policy simultaneously. Choose one.")
        
        # HACK: We parse again the cli args here to get the pretrained path if there was one.
        policy_path = parser.get_path_arg("policy")
        if policy_path:
            cli_overrides = parser.get_cli_overrides("policy")
            self.policy = PreTrainedConfig.from_pretrained(policy_path, cli_overrides=cli_overrides)
            self.policy.pretrained_path = policy_path

    @classmethod
    def __get_path_fields__(cls) -> list[str]:
        """This enables the parser to load config from the policy using `--policy.path=local/dir`"""
        return ["policy"]


class BiSO100Robot:
    """BiSO100 robot wrapper that follows LeRobot Robot interface"""
    
    name = "bi_so100_maniskill"
    robot_type = "bi_so100_maniskill"
    
    def __init__(self, config: BiSO100RobotConfig):
        self.config = config
        self.env = None
        self.robot = None
        self.teleops = []
        self.calibrations = {}
        self._connected = False
        
        # Joint control
        self.target_joints = np.zeros(12)
        self.p_gain = np.ones(12)
        self.p_gain[[5, 11]] = 0.1  # Lower gain for grippers
        
        # Set up leader to arm mapping (assumes first leader controls left arm, second controls right)
        if config.leader_ids and len(config.leader_ids) == 2:
            self.leader_to_arm_map = {
                config.leader_ids[0]: "left", 
                config.leader_ids[1]: "right"
            }
        else:
            self.leader_to_arm_map = {}
        
        # Load calibrations if provided
        if config.calibration_files and config.leader_ids:
            for leader_id, calib_file in zip(config.leader_ids, config.calibration_files):
                calib_data = self._load_calibration(calib_file)
                
                # Check if calibration needs remapping
                calibrated_arm = calib_data["metadata"].get("virtual_arm")
                target_arm = self.leader_to_arm_map.get(leader_id)
                
                if calibrated_arm and target_arm and calibrated_arm != target_arm:
                    logger.warning(
                        f"Calibration file for leader '{leader_id}' is for '{calibrated_arm}' arm, "
                        f"but it will control the '{target_arm}' arm. Remapping calibration data."
                    )
                    calib_data = self._remap_calibration_data(calib_data, source_arm=calibrated_arm, target_arm=target_arm)
                
                self.calibrations[leader_id] = calib_data
    
    def _load_calibration(self, calibration_file: str) -> Dict[str, Any]:
        """Load calibration data from file"""
        calibration_path = Path(calibration_file)
        if not calibration_path.exists():
            raise FileNotFoundError(f"Calibration file not found: {calibration_file}")
        
        with open(calibration_path, 'r') as f:
            calibration_data = json.load(f)
        
        logger.info(f"Loaded calibration from: {calibration_file}")
        return calibration_data
    
    def _remap_calibration_data(self, calib_data: Dict[str, Any], source_arm: str, target_arm: str) -> Dict[str, Any]:
        """Dynamically remap calibration data from one arm to another."""
        if source_arm == target_arm:
            return calib_data

        remapped_calib = calib_data.copy()
        new_calib_data = {}
        new_joint_mapping = {}

        if source_arm == "right" and target_arm == "left":
            index_offset, suffix_to_remove, suffix_to_add = -6, "_2", ""
        elif source_arm == "left" and target_arm == "right":
            index_offset, suffix_to_remove, suffix_to_add = 6, "", "_2"
        else:
            logger.error(f"Unsupported calibration remapping from '{source_arm}' to '{target_arm}'")
            return calib_data

        for leader_joint, calib in calib_data["calibration_data"].items():
            new_calib = calib.copy()
            original_vjoint = calib["virtual_joint"]
            
            new_vjoint = original_vjoint.removesuffix(suffix_to_remove) if suffix_to_remove else original_vjoint
            new_vjoint += suffix_to_add
            
            new_calib["virtual_joint"] = new_vjoint
            new_calib["virtual_joint_index"] = calib["virtual_joint_index"] + index_offset
            
            new_calib_data[leader_joint] = new_calib
            new_joint_mapping[leader_joint] = new_vjoint

        remapped_calib["calibration_data"] = new_calib_data
        remapped_calib["metadata"]["joint_mapping"] = new_joint_mapping
        remapped_calib["metadata"]["virtual_arm"] = target_arm
        remapped_calib["metadata"]["arm_mapping"] = f"{calib_data['metadata']['leader_id']} -> {target_arm} (remapped)"
        
        return remapped_calib

    def _process_camera_image(self, img):
        """Process camera image to handle ManiSkill's batched format and CUDA tensors"""
        # Handle CUDA tensors - move to CPU first
        if hasattr(img, 'device') and 'cuda' in str(img.device):
            img = img.cpu()
        
        # Convert to numpy
        if hasattr(img, 'numpy'):
            img = img.numpy()
        
        # Remove batch dimension if present
        while img.ndim == 4 and img.shape[0] == 1:
            img = img.squeeze(0)
        
        # Ensure proper data type
        if img.dtype != np.uint8:
            if img.max() <= 1.0:  # Assume normalized
                img = (img * 255).astype(np.uint8)
            else:
                img = img.astype(np.uint8)
        
        return img
    
    def _detect_camera_features_from_observation(self, observation: dict) -> dict:
        """Detect camera features from observation data"""
        camera_features = {}
        for key, value in observation.items():
            if isinstance(value, np.ndarray) and len(value.shape) == 3:  # Assume RGB images
                camera_features[key] = value.shape  # (height, width, channels)
        return camera_features
    
    @cached_property
    def observation_features(self) -> dict[str, type | tuple]:
        """Return observation features"""
        features = {}
        
        # Joint features (12 DOF)
        joint_names = [
            "left_shoulder_pan", "left_shoulder_lift", "left_elbow_flex", 
            "left_wrist_flex", "left_wrist_roll", "left_gripper",
            "right_shoulder_pan", "right_shoulder_lift", "right_elbow_flex",
            "right_wrist_flex", "right_wrist_roll", "right_gripper"
        ]
        
        for joint_name in joint_names:
            features[f"{joint_name}.pos"] = float
        
        # Camera features (detected dynamically)
        # Note: In practice, these will be properly set via hw_to_dataset_features
        for camera_name in self.cameras.keys():
            camera_info = self.cameras[camera_name]
            features[camera_name] = (camera_info["height"], camera_info["width"], 3)
        
        return features
    
    @cached_property
    def cameras(self) -> dict[str, any]:
        """Return camera information for proper threading calculation"""
        cameras = {}
        
        # Robot wrist cameras (mounted on grippers)
        cameras["wrist_camera_1"] = {"width": 640, "height": 480}
        cameras["wrist_camera_2"] = {"width": 640, "height": 480}
        
        # Human render cameras (for visualization/recording) 
        cameras["top_camera"] = {"width": 640, "height": 480}
        cameras["side_camera"] = {"width": 640, "height": 480}
        
        return cameras
    
    @cached_property
    def action_features(self) -> dict[str, type]:
        """Return action features"""
        joint_names = [
            "left_shoulder_pan", "left_shoulder_lift", "left_elbow_flex", 
            "left_wrist_flex", "left_wrist_roll", "left_gripper",
            "right_shoulder_pan", "right_shoulder_lift", "right_elbow_flex",
            "right_wrist_flex", "right_wrist_roll", "right_gripper"
        ]
        
        return {f"{joint_name}.pos": float for joint_name in joint_names}
    
    @property
    def robot_type(self) -> str:
        return self.name
    
    @property
    def is_connected(self) -> bool:
        return self._connected
    
    def connect(self, calibrate: bool = True, use_teleop: bool = True) -> None:
        """Connect to the ManiSkill environment and optionally teleoperators"""
        if self.is_connected:
            raise DeviceAlreadyConnectedError(f"{self} already connected")
        
        # Initialize environment
        self.env = gym.make(
            self.config.env_id,
            obs_mode=self.config.obs_mode,
            render_mode=self.config.render_mode,
            sim_backend=self.config.sim_backend,
            robot_uids=self.config.robot_uids
        )
        
        obs, _ = self.env.reset()
        
        # Get robot
        if hasattr(self.env.unwrapped, "agent"):
            self.robot = self.env.unwrapped.agent.robot
        else:
            self.robot = self.env.unwrapped.agents[0]
        
        # Initialize target_joints with current robot position (crucial for proper control)
        current_joints = self._get_mapped_joints()
        self.target_joints = current_joints.copy()
        logger.info(f"Initialized target joints: {self.target_joints}")
        logger.info(f"P-gains: {self.p_gain}")
        
        # Initialize teleoperators only if requested and configured
        if use_teleop and self.config.leader_ids and self.config.teleop_ports:
            logger.info(f"Connecting teleoperators: {self.config.leader_ids} on ports {self.config.teleop_ports}")
            for leader_id, port in zip(self.config.leader_ids, self.config.teleop_ports):
                config = SO100LeaderConfig(port=port, id=leader_id)
                teleop = make_teleoperator_from_config(config)
                teleop.connect(calibrate=calibrate)
                self.teleops.append(teleop)
                logger.info(f"Connected teleoperator {leader_id} on {port}")
        elif use_teleop:
            logger.warning("Teleoperators requested but not properly configured - leader_ids or teleop_ports missing")
        else:
            logger.info("Teleoperators disabled - using policy or manual control mode")
        
        self._connected = True
        logger.info(f"{self} connected to ManiSkill environment")
    
    def disconnect(self) -> None:
        """Disconnect from the environment"""
        if not self.is_connected:
            raise DeviceNotConnectedError(f"{self} is not connected")
        
        # Disconnect teleoperators
        for teleop in self.teleops:
            teleop.disconnect()
        
        # Close environment
        if self.env:
            self.env.close()
            
        self._connected = False
        logger.info(f"{self} disconnected")
    
    def _get_mapped_joints(self):
        """Get robot joints in the correct order (same as existing teleoperation)"""
        full_joints = self.robot.get_qpos()
        if hasattr(full_joints, 'numpy'):
            full_joints = full_joints.numpy()
        if full_joints.ndim > 1:
            full_joints = full_joints.squeeze()
        
        mapped_joints = np.zeros(12)
        if len(full_joints) >= 12:
            # This mapping is from the existing teleoperation script
            mapped_joints[0:6] = full_joints[[0, 2, 4, 6, 8, 10]]    # Left arm
            mapped_joints[6:12] = full_joints[[1, 3, 5, 7, 9, 11]]   # Right arm
        return mapped_joints
    
    def _apply_calibration(self, leader_id: str, leader_action: Dict[str, float]):
        """Apply calibration mapping from leader to virtual arm"""
        if leader_id not in self.calibrations:
            return
            
        calibration = self.calibrations[leader_id]
        
        for leader_joint, leader_pos_deg in leader_action.items():
            leader_joint_name = leader_joint.removesuffix('.pos')
            if leader_joint_name in calibration["calibration_data"]:
                calib = calibration["calibration_data"][leader_joint_name]
                leader_pos_rad = np.radians(leader_pos_deg)
                
                virtual_pos_rad = calib["scale_factor"] * leader_pos_rad + calib["offset"]
                
                if leader_joint_name == "gripper":
                    virtual_range_min = calib.get("virtual_range_min", 0.0)
                    virtual_range_max = calib.get("virtual_range_max", 1.7)
                    virtual_pos_rad = np.interp(virtual_pos_rad, [virtual_range_min, virtual_range_max], [0.0, 1.7])
                
                self.target_joints[calib["virtual_joint_index"]] = virtual_pos_rad
    
    def get_observation(self) -> dict[str, Any]:
        """Get current observation from the environment"""
        if not self.is_connected:
            raise DeviceNotConnectedError(f"{self} is not connected")
        
        obs = self.env.get_obs()
        
        # Get joint positions
        joints = self._get_mapped_joints()
        observation = {}
        
        # Add joint positions (12 DOF total)
        joint_names = [
            "left_shoulder_pan", "left_shoulder_lift", "left_elbow_flex", 
            "left_wrist_flex", "left_wrist_roll", "left_gripper",
            "right_shoulder_pan", "right_shoulder_lift", "right_elbow_flex",
            "right_wrist_flex", "right_wrist_roll", "right_gripper"
        ]
        
        for i, joint_name in enumerate(joint_names):
            observation[f"{joint_name}.pos"] = float(joints[i])
        
        # Add camera images if available
        if "sensor_data" in obs:
            sensor_data = obs["sensor_data"]
            
            # Robot wrist cameras
            if "wrist_camera_1" in sensor_data:
                img = sensor_data["wrist_camera_1"]["rgb"]
                img = self._process_camera_image(img)
                observation["wrist_camera_1"] = img
                
            if "wrist_camera_2" in sensor_data:
                img = sensor_data["wrist_camera_2"]["rgb"]
                img = self._process_camera_image(img)
                observation["wrist_camera_2"] = img
                
            # Environment scene camera
            if "top_camera" in sensor_data:
                img = sensor_data["top_camera"]["rgb"]
                img = self._process_camera_image(img)
                observation["top_camera"] = img

            if "side_camera" in sensor_data:
                img = sensor_data["side_camera"]["rgb"]
                img = self._process_camera_image(img)
                observation["side_camera"] = img
        
        return observation
    
    def send_action(self, action: dict[str, Any]) -> dict[str, Any]:
        """Send action to the ManiSkill environment using the provided action"""
        if not self.is_connected:
            raise DeviceNotConnectedError(f"{self} is not connected")
        
        logger.debug(f"Send action called with: {action}")
        
        # Define joint names for mapping
        joint_names = [
            "left_shoulder_pan", "left_shoulder_lift", "left_elbow_flex", 
            "left_wrist_flex", "left_wrist_roll", "left_gripper",
            "right_shoulder_pan", "right_shoulder_lift", "right_elbow_flex",
            "right_wrist_flex", "right_wrist_roll", "right_gripper"
        ]
        
        # Update target_joints from the provided action (works for both teleop and policy)
        for i, joint_name in enumerate(joint_names):
            joint_key = f"{joint_name}.pos"
            if joint_key in action:
                self.target_joints[i] = action[joint_key]
        
        # Apply proportional control
        current_joints = self._get_mapped_joints()
        control_action = np.zeros(12)
        for i in range(12):
            control_action[i] = self.p_gain[i] * (self.target_joints[i] - current_joints[i])
        
        logger.debug(f"Target joints: {self.target_joints}")
        logger.debug(f"Current joints: {current_joints}")
        logger.debug(f"Control action: {control_action}")
        
        # Send to environment
        obs, reward, terminated, truncated, info = self.env.step(control_action)
        if self.config.render_mode == "human":
            self.env.render()
        
        # Return the action that was actually sent (for dataset recording)
        sent_action = {}
        for i, joint_name in enumerate(joint_names):
            sent_action[f"{joint_name}.pos"] = float(self.target_joints[i])
        
        return sent_action
    
    def __repr__(self):
        return f"{self.__class__.__name__}({self.config.env_id})"


class BiSO100Teleoperator:
    """Teleoperator that gets actions from the robot's real teleoperators or provides dummy actions for policy mode"""
    
    def __init__(self, robot: BiSO100Robot, use_real_teleop: bool = True):
        self.robot = robot
        self.use_real_teleop = use_real_teleop
    
    @property
    def action_features(self) -> dict[str, type]:
        return self.robot.action_features
    
    @property
    def feedback_features(self) -> dict[str, type]:
        return {}
    
    @property
    def is_connected(self) -> bool:
        return True  # Always connected since robot handles teleoperators
    
    def connect(self, calibrate: bool = True) -> None:
        pass  # Robot handles connection
    
    def disconnect(self) -> None:
        pass  # Robot handles disconnection
    
    def get_action(self) -> dict[str, float]:
        """Get action from robot's real teleoperators or return current state for policy mode"""
        
        if self.use_real_teleop and self.robot.teleops:
            # Get fresh actions from teleoperators and apply calibration (teleop mode)
            leader_actions = {}
            for teleop in self.robot.teleops:
                leader_id = teleop.config.id
                leader_action = teleop.get_action()
                leader_actions[leader_id] = leader_action
                logger.debug(f"Raw leader action from {leader_id}: {leader_action}")
            
            # Apply calibration for each leader's action (following working implementation pattern)
            for leader_id, leader_action in leader_actions.items():
                if leader_id in self.robot.calibrations:
                    self.robot._apply_calibration(leader_id, leader_action)
            
            logger.debug(f"Target joints after calibration: {self.robot.target_joints}")
        else:
            # Policy mode - return current target joints (no teleoperator input needed)
            logger.debug("Policy mode - no teleoperator input required")
        
        # Return the current target joints as the action (for dataset recording)
        joint_names = [
            "left_shoulder_pan", "left_shoulder_lift", "left_elbow_flex", 
            "left_wrist_flex", "left_wrist_roll", "left_gripper",
            "right_shoulder_pan", "right_shoulder_lift", "right_elbow_flex",
            "right_wrist_flex", "right_wrist_roll", "right_gripper"
        ]
        
        action = {}
        for i, joint_name in enumerate(joint_names):
            action[f"{joint_name}.pos"] = float(self.robot.target_joints[i])
        
        return action
    
    def send_feedback(self, feedback: dict[str, float]) -> None:
        pass


@safe_stop_image_writer
def record_loop(
    robot: BiSO100Robot,
    events: dict,
    fps: int,
    dataset: LeRobotDataset | None = None,
    teleop: BiSO100Teleoperator | None = None,
    policy: PreTrainedPolicy | None = None,
    control_time_s: int | None = None,
    single_task: str | None = None,
    display_data: bool = False,
):
    """Main recording loop following LeRobot pattern"""
    
    if dataset is not None and dataset.fps != fps:
        raise ValueError(f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps}).")

    # if policy is given it needs cleaning up
    if policy is not None:
        policy.reset()

    timestamp = 0
    robot.env.reset()
    start_episode_t = time.perf_counter()
    
    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        # Get observation
        observation = robot.get_observation()

        if policy is not None or dataset is not None:
            observation_frame = build_dataset_frame(dataset.features, observation, prefix="observation")

        # Get action from policy or teleoperator
        if policy is not None:
            action_values = predict_action(
                observation_frame,
                policy,
                get_safe_torch_device(policy.config.device),
                policy.config.use_amp,
                task=single_task,
                robot_type=robot.robot_type,
            )
            action = {key: action_values[i].item() for i, key in enumerate(robot.action_features)}
        elif teleop is not None and teleop.use_real_teleop:
            # Get action from teleoperator (only if real teleop is enabled)
            action = teleop.get_action()
        else:
            # Manual mode - use current robot state
            action = {}
            joint_names = [
                "left_shoulder_pan", "left_shoulder_lift", "left_elbow_flex", 
                "left_wrist_flex", "left_wrist_roll", "left_gripper",
                "right_shoulder_pan", "right_shoulder_lift", "right_elbow_flex",
                "right_wrist_flex", "right_wrist_roll", "right_gripper"
            ]
            current_joints = robot._get_mapped_joints()
            for i, joint_name in enumerate(joint_names):
                action[f"{joint_name}.pos"] = float(current_joints[i])

        # Send action to robot (this updates teleoperators and sends to env)
        sent_action = robot.send_action(action)

        if dataset is not None:
            action_frame = build_dataset_frame(dataset.features, sent_action, prefix="action")
            frame = {**observation_frame, **action_frame}
            dataset.add_frame(frame, task=single_task)

        # Add rerun visualization support like official LeRobot
        if display_data and RERUN_AVAILABLE:
            logger.debug(f"Logging {len(observation)} observations and {len(sent_action)} actions to rerun")
            for obs, val in observation.items():
                if isinstance(val, float):
                    rr.log(f"observation.{obs}", rr.Scalar(val))
                elif isinstance(val, np.ndarray):
                    rr.log(f"observation.{obs}", rr.Image(val), static=True)
            for act, val in sent_action.items():
                if isinstance(val, float):
                    rr.log(f"action.{act}", rr.Scalar(val))
        elif display_data and not RERUN_AVAILABLE:
            logger.warning("Display requested but rerun is not available. Install with: pip install rerun-sdk")

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t
        if events["exit_early"]:
            events["exit_early"] = False
            break


@parser.wrap()
def record(cfg: RecordConfig) -> LeRobotDataset:
    """Main recording function following LeRobot pattern"""
    
    init_logging()
    logging.info(pformat(asdict(cfg)))
    
    # Initialize rerun for data visualization if requested
    if cfg.display_data and RERUN_AVAILABLE:
        _init_rerun(session_name="recording")

    # Create robot
    robot = BiSO100Robot(cfg.robot)
    
    # Determine if we're using teleoperators or policy
    use_teleop = cfg.policy is None  # Use teleop only if no policy is provided
    
    # Always create teleoperator object, but configure it based on mode
    # This ensures display functionality works in all modes
    teleop = BiSO100Teleoperator(robot, use_real_teleop=use_teleop)

    # Create dataset features using proper hw_to_dataset_features
    action_features = hw_to_dataset_features(robot.action_features, "action", cfg.dataset.video)
    obs_features = hw_to_dataset_features(robot.observation_features, "observation", cfg.dataset.video)
    dataset_features = {**action_features, **obs_features}

    if cfg.resume:
        dataset = LeRobotDataset(
            cfg.dataset.repo_id,
            root=cfg.dataset.root,
        )
        
        # Use dynamic camera counting like official LeRobot
        if hasattr(robot, "cameras") and len(robot.cameras) > 0:
            dataset.start_image_writer(
                num_processes=cfg.dataset.num_image_writer_processes,
                num_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
            )
        sanity_check_dataset_robot_compatibility(dataset, robot, cfg.dataset.fps, dataset_features)
    else:
        # Create empty dataset
        sanity_check_dataset_name(cfg.dataset.repo_id, cfg.policy)
        dataset = LeRobotDataset.create(
            cfg.dataset.repo_id,
            cfg.dataset.fps,
            root=cfg.dataset.root,
            robot_type=robot.robot_type,
            features=dataset_features,
            use_videos=cfg.dataset.video,
            image_writer_processes=cfg.dataset.num_image_writer_processes,
            image_writer_threads=cfg.dataset.num_image_writer_threads_per_camera * len(robot.cameras),
        )

    # Load pretrained policy
    policy = None if cfg.policy is None else make_policy(cfg.policy, ds_meta=dataset.meta)

    # Connect devices - only use teleoperators if not using policy
    robot.connect(use_teleop=use_teleop)
    
    # Log the control mode
    if policy is not None:
        logger.info("ü§ñ Using POLICY mode - no teleoperators needed")
        logger.info(f"Policy path: {cfg.policy.pretrained_path if hasattr(cfg.policy, 'pretrained_path') else 'N/A'}")
    elif use_teleop:
        logger.info("üéÆ Using TELEOPERATOR mode")
        logger.info(f"Teleoperators configured: {len(robot.teleops)} connected")
    else:
        logger.info("üñ±Ô∏è Using MANUAL mode")
    
    # Log display configuration
    if cfg.display_data:
        if RERUN_AVAILABLE:
            logger.info("üì∫ Display enabled - rerun visualization active")
        else:
            logger.warning("üì∫ Display requested but rerun not available - install with: pip install rerun-sdk")
    else:
        logger.info("üì∫ Display disabled")

    # Setup keyboard listener
    listener, events = init_keyboard_listener()

    try:
        for recorded_episodes in range(cfg.dataset.num_episodes):
            log_say(f"Recording episode {dataset.num_episodes}", cfg.play_sounds)
            
            record_loop(
                robot=robot,
                events=events,
                fps=cfg.dataset.fps,
                teleop=teleop,
                policy=policy,
                dataset=dataset,
                control_time_s=cfg.dataset.episode_time_s,
                single_task=cfg.dataset.single_task,
                display_data=cfg.display_data,
            )

            # Execute a few seconds without recording to give time to manually reset the environment
            if not events["stop_recording"] and (
                (recorded_episodes < cfg.dataset.num_episodes - 1) or events["rerecord_episode"]
            ):
                log_say("Reset the environment", cfg.play_sounds)
                # Reset environment
                time.sleep(1)

            if events["rerecord_episode"]:
                log_say("Re-record episode", cfg.play_sounds)
                events["rerecord_episode"] = False
                events["exit_early"] = False
                dataset.clear_episode_buffer()
                continue

            dataset.save_episode()

            if events["stop_recording"]:
                break

    finally:
        log_say("Stop recording", cfg.play_sounds, blocking=True)

        robot.disconnect()

        if not is_headless() and listener is not None:
            listener.stop()

        # Properly close rerun to avoid gRPC errors
        if cfg.display_data and RERUN_AVAILABLE:
            try:
                rr.disconnect()
            except Exception as e:
                logger.warning(f"Error closing rerun: {e}")

    if cfg.dataset.push_to_hub:
        dataset.push_to_hub(tags=cfg.dataset.tags, private=cfg.dataset.private)

    log_say("Exiting", cfg.play_sounds)
    return dataset


if __name__ == "__main__":
    record() 